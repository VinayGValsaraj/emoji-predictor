{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from utils import Indexer\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from tokenizer import tokenizer as vinay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can', 'not']\n"
     ]
    }
   ],
   "source": [
    "v = vinay.TweetTokenizer(regularize=True, preserve_len=False)\n",
    "print (v.tokenize(\"can't\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😊\n"
     ]
    }
   ],
   "source": [
    "indexer = Indexer()\n",
    "with open('indexer_15_dups.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        indexer.add_and_get_index(row[0])\n",
    "        \n",
    "print(indexer.get_object(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPoint():\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnts = Counter()\n",
    "def count_words(text):\n",
    "    words = v.tokenize(text)\n",
    "    #print(words)\n",
    "    for word in words:\n",
    "        word_cnts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open('dataset_15_dups.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        count_words(row[1])\n",
    "        dataset.append(DataPoint(row[1], int(row[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2377113"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    temp = data.text.replace(\"’\", \"'\")\n",
    "    words = v.tokenize(temp)\n",
    "    for idx, word in enumerate(words):\n",
    "        if word_cnts[word] <= 10:\n",
    "            words[idx] = \"\"\n",
    "    data.text = \" \".join(word for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said michael was from texas\n",
      "0\n",
      "true facts\n",
      "1\n",
      "what did y'all call this back then in school me \n",
      "0\n",
      "when you fall for someone everything about them becomes beautiful\n",
      "2\n",
      "personalize yours etsyetsymntt etsy ebay etsyretwt epiconetsy etsyaaa bride\n",
      "3\n",
      "personalize yours etsyetsymntt etsy ebay etsyretwt epiconetsy etsyaaa bride\n",
      "4\n",
      "why be mad if he keeping it\n",
      "1\n",
      "appreciate ya\n",
      "1\n",
      "i do not see any boyfriends getting love for sweetest day it is rough out here\n",
      "0\n",
      "we are keeping up with the lead 20 more minutes to go\n",
      "3\n",
      "when you see a fat ass pothole but it is too late\n",
      "0\n",
      "blessings on blessings\n",
      "4\n",
      "ellis was two weeks late and my feet were like fucking  i will never ever do it again can not wait to hear your news xx\n",
      "0\n",
      "shiiit if you know you know these hoes each hit different\n",
      "6\n",
      "shiiit if you know you know these hoes each hit different\n",
      "7\n",
      "great\n",
      "8\n",
      "mother elephant giving birth and calling the herd to surround the baby to protect it\n",
      "9\n",
      "mother elephant giving birth and calling the herd to surround the baby to protect it\n",
      "7\n",
      "“ my first doe mommy is going to flip out ”\n",
      "6\n",
      "you go to less games than i do pipe down\n",
      "0\n",
      "aim to the right ffs\n",
      "0\n",
      " you are just like the other  amp crying repeating a\n",
      "7\n",
      "thought i tagged you\n",
      "7\n",
      "look out ref\n",
      "0\n",
      "“ oh shit this bitch hit me wit her fucking car ”\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for dp in dataset[:25]:\n",
    "    print (dp.text)\n",
    "    print (dp.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaned_dataset_15_dups.csv', 'w') as f:\n",
    "    for datapoint in dataset:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
