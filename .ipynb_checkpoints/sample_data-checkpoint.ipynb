{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import Indexer\n",
    "from random import shuffle\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPoint():\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = []\n",
    "tknzr = TweetTokenizer()\n",
    "with open('cleaned_dataset.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        tokenized = tknzr.tokenize(row[1])\n",
    "        if set(tokenized) == set([\"UNK\"]):\n",
    "            continue\n",
    "        cleaned_dataset.append(DataPoint(row[1], int(row[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3331729"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = Indexer()\n",
    "with open('indexer.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        indexer.add_and_get_index(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ğŸ˜‚', 'ğŸ‘', 'ğŸ’™', 'ğŸ’¯', 'ğŸ˜', 'ğŸ’•', 'ğŸ”¥', 'ğŸ˜', 'ğŸ’€', 'ğŸ’œ', 'ğŸ‘', '\\U0001f937', 'ğŸ¤”', 'ğŸ˜©', 'ğŸ˜­', '\\U0001f923', 'ğŸ˜Š', 'â¤', 'ğŸ™Œ', 'âœ¨', 'ğŸ™', 'ğŸ‘€', 'ğŸ˜', 'ğŸ‘‰', 'ğŸ™„', 'ğŸ‰', 'ğŸ˜˜', 'ğŸ’–', 'ğŸƒ', '\\U0001f926']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ğŸ‘€': 69302, 'âœ¨': 91086, 'ğŸ˜˜': 64826, 'ğŸ’•': 105534, 'ğŸ™Œ': 60728, 'ğŸ˜Š': 76585, 'ğŸ™': 100502, 'ğŸ˜': 205427, 'ğŸ”¥': 177532, 'ğŸ’¯': 61553, 'â¤': 287120, 'ğŸ‘‰': 60217, 'ğŸ‰': 61071, 'ğŸ’œ': 88608, 'ğŸ˜': 46994, 'ğŸ˜': 51175, 'ğŸ‘': 62881, 'ğŸ˜‚': 618194, 'ğŸ’–': 53127, 'ğŸƒ': 66428, '\\U0001f923': 103328, '\\U0001f937': 69786, 'ğŸ˜©': 88437, 'ğŸ˜­': 297546, 'ğŸ’™': 66119, 'ğŸ‘': 57308, 'ğŸ¤”': 63475, 'ğŸ™„': 50626, '\\U0001f926': 57209, 'ğŸ’€': 69005}\n"
     ]
    }
   ],
   "source": [
    "emoji_sample_count = {}\n",
    "\n",
    "for dp in cleaned_dataset:\n",
    "    emoji_sample_count[indexer.get_object(dp.label)] = emoji_sample_count.get(indexer.get_object(dp.label), 0) + 1\n",
    "    \n",
    "print (emoji_sample_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said michael was from texas\n",
      "united vibe they so cuteee awwww xfactor\n",
      "happy 47th birthday to snoop dogg\n",
      "true facts\n",
      "what did y'all call this back then in school me fraps\n",
      "let â€™ s goooooo for new artist of the year at the amas to vote\n",
      "queen but uncrowned\n",
      "atl in two weeks\n",
      "look it it's freakin bats i love halloween\n",
      "sports day\n"
     ]
    }
   ],
   "source": [
    "for dp in cleaned_dataset[:5]:\n",
    "    print (dp.text)\n",
    "shuffle(cleaned_dataset)\n",
    "for dp in cleaned_dataset[:5]:\n",
    "    print (dp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3331729\n"
     ]
    }
   ],
   "source": [
    "print (len(cleaned_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 50000, 1: 50000, 2: 50000, 3: 50000, 4: 50000, 5: 50000, 6: 50000, 7: 50000, 8: 50000, 9: 50000, 10: 50000, 11: 50000, 12: 50000, 13: 50000, 14: 50000, 15: 50000, 16: 50000, 17: 50000, 18: 50000, 19: 50000, 20: 50000, 21: 50000, 22: 46994, 23: 50000, 24: 50000, 25: 50000, 26: 50000, 27: 50000, 28: 50000, 29: 50000}\n",
      "1496994\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = []\n",
    "emoji_sample_counter = {}\n",
    "\n",
    "for dp in cleaned_dataset:\n",
    "    if dp.label in emoji_sample_counter:\n",
    "        if emoji_sample_counter[dp.label] < 50000:\n",
    "            sample_dataset.append(dp)\n",
    "            emoji_sample_counter[dp.label] += 1\n",
    "    else:\n",
    "        emoji_sample_counter[dp.label] = 1\n",
    "        sample_dataset.append(dp)\n",
    "print (emoji_sample_counter) \n",
    "print (len(sample_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197595\n",
      "149700\n",
      "149699\n"
     ]
    }
   ],
   "source": [
    "shuffle(sample_dataset)\n",
    "train_split = int(round(0.8*len(sample_dataset)))\n",
    "dev_split = train_split + int(round(0.5 * (len(sample_dataset) - train_split)))\n",
    "\n",
    "train_data = sample_dataset[:train_split]\n",
    "dev_data = sample_dataset[train_split:dev_split]\n",
    "test_data = sample_dataset[dev_split:]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(dev_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.csv', 'w') as f:\n",
    "    for datapoint in train_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dev.csv', 'w') as f:\n",
    "    for datapoint in dev_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.csv', 'w') as f:\n",
    "    for datapoint in test_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
