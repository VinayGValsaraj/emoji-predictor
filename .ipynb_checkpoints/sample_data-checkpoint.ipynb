{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import Indexer\n",
    "from random import shuffle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPoint():\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = []\n",
    "with open('cleaned_dataset_15_dups.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        if row[1].isspace() or row[1] == \"\":\n",
    "            continue\n",
    "        cleaned_dataset.append(DataPoint(row[1], int(row[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2366550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = Indexer()\n",
    "with open('indexer_15_dups.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    temp = [\"\"] * 15\n",
    "    for row in reader:\n",
    "        temp[int(row[1])] = row[0]\n",
    "        \n",
    "    for emoji in temp:\n",
    "        indexer.add_and_get_index(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['😊', '😍', '💯', '😘', '😭', '🎃', '👀', '😩', '💀', '💕', '😂', '🙏', '❤', '🔥', '🙄']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'🙏': 69694, '🙄': 66872, '❤': 50890, '🎃': 69921, '💀': 78093, '😘': 179419, '😭': 108161, '🔥': 66098, '💯': 208251, '😍': 62728, '😩': 301087, '😂': 101988, '💕': 290777, '😊': 623485, '👀': 89086}\n"
     ]
    }
   ],
   "source": [
    "emoji_sample_count = {}\n",
    "\n",
    "for dp in cleaned_dataset:\n",
    "    emoji_sample_count[indexer.get_object(dp.label)] = emoji_sample_count.get(indexer.get_object(dp.label), 0) + 1\n",
    "    \n",
    "print (emoji_sample_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do not fly at night cowbellinthesky\n",
      "yanks getting it raw in da ass no lube\n",
      "super cute thalaivaaa cuteness overloaded vijay thalapathy\n",
      "hbd young  have a blessed one\n",
      "love wen plays with her pretty pussy\n",
      "please help to save little cute  now\n",
      "who's excited for our instore party tomorrow from  at  east square remember the first 25 wsu studen\n",
      "i can write an a essay for you legit guarantees 0 plagiarism √ √ delivered on time proper formatting amp  ci\n",
      "great\n",
      "everyone who goes through the tunnel gets a wash and free plasters i love this message\n"
     ]
    }
   ],
   "source": [
    "for dp in cleaned_dataset[:5]:\n",
    "    print (dp.text)\n",
    "shuffle(cleaned_dataset)\n",
    "for dp in cleaned_dataset[:5]:\n",
    "    print (dp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3330595\n"
     ]
    }
   ],
   "source": [
    "print (len(cleaned_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{20: 50000, 25: 50000, 3: 50000, 0: 50000, 17: 50000, 4: 50000, 5: 50000, 28: 50000, 23: 50000, 6: 50000, 11: 50000, 9: 50000, 10: 50000, 13: 50000, 22: 46967, 19: 50000, 7: 50000, 29: 50000, 14: 50000, 15: 50000, 21: 50000, 24: 50000, 26: 50000, 27: 50000, 12: 50000, 1: 50000, 2: 50000, 8: 50000, 18: 50000, 16: 50000}\n",
      "1496967\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = []\n",
    "emoji_sample_counter = {}\n",
    "\n",
    "for dp in cleaned_dataset:\n",
    "    if dp.label in emoji_sample_counter:\n",
    "        if emoji_sample_counter[dp.label] < 50000:\n",
    "            sample_dataset.append(dp)\n",
    "            emoji_sample_counter[dp.label] += 1\n",
    "    else:\n",
    "        emoji_sample_counter[dp.label] = 1\n",
    "        sample_dataset.append(dp)\n",
    "print (emoji_sample_counter) \n",
    "print (len(sample_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197574\n",
      "149696\n",
      "149697\n"
     ]
    }
   ],
   "source": [
    "shuffle(sample_dataset)\n",
    "train_split = int(round(0.8*len(sample_dataset)))\n",
    "dev_split = train_split + int(round(0.5 * (len(sample_dataset) - train_split)))\n",
    "\n",
    "train_data = sample_dataset[:train_split]\n",
    "dev_data = sample_dataset[train_split:dev_split]\n",
    "test_data = sample_dataset[dev_split:]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(dev_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/train_cont.csv', 'w') as f:\n",
    "    for datapoint in train_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/dev_cont.csv', 'w') as f:\n",
    "    for datapoint in dev_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/test_cont.csv', 'w') as f:\n",
    "    for datapoint in test_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
