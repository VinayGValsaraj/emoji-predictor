{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import Indexer\n",
    "from random import shuffle\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPoint():\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = []\n",
    "tknzr = TweetTokenizer()\n",
    "with open('cleaned_dataset.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        tokenized = tknzr.tokenize(row[1])\n",
    "        if set(tokenized) == set([\"UNK\"]):\n",
    "            continue\n",
    "        cleaned_dataset.append(DataPoint(row[1], int(row[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3331729"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = Indexer()\n",
    "with open('indexer.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        indexer.add_and_get_index(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['😂', '👏', '💙', '💯', '😍', '💕', '🔥', '😎', '💀', '💜', '👍', '\\U0001f937', '🤔', '😩', '😭', '\\U0001f923', '😊', '❤', '🙌', '✨', '🙏', '👀', '😁', '👉', '🙄', '🎉', '😘', '💖', '🎃', '\\U0001f926']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'👀': 69302, '✨': 91086, '😘': 64826, '💕': 105534, '🙌': 60728, '😊': 76585, '🙏': 100502, '😍': 205427, '🔥': 177532, '💯': 61553, '❤': 287120, '👉': 60217, '🎉': 61071, '💜': 88608, '😁': 46994, '😎': 51175, '👏': 62881, '😂': 618194, '💖': 53127, '🎃': 66428, '\\U0001f923': 103328, '\\U0001f937': 69786, '😩': 88437, '😭': 297546, '💙': 66119, '👍': 57308, '🤔': 63475, '🙄': 50626, '\\U0001f926': 57209, '💀': 69005}\n"
     ]
    }
   ],
   "source": [
    "emoji_sample_count = {}\n",
    "\n",
    "for dp in cleaned_dataset:\n",
    "    emoji_sample_count[indexer.get_object(dp.label)] = emoji_sample_count.get(indexer.get_object(dp.label), 0) + 1\n",
    "    \n",
    "print (emoji_sample_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said michael was from texas\n",
      "united vibe they so cuteee awwww xfactor\n",
      "happy 47th birthday to snoop dogg\n",
      "true facts\n",
      "what did y'all call this back then in school me fraps\n",
      "let ’ s goooooo for new artist of the year at the amas to vote\n",
      "queen but uncrowned\n",
      "atl in two weeks\n",
      "look it it's freakin bats i love halloween\n",
      "sports day\n"
     ]
    }
   ],
   "source": [
    "for dp in cleaned_dataset[:5]:\n",
    "    print (dp.text)\n",
    "shuffle(cleaned_dataset)\n",
    "for dp in cleaned_dataset[:5]:\n",
    "    print (dp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3331729\n"
     ]
    }
   ],
   "source": [
    "print (len(cleaned_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 50000, 1: 50000, 2: 50000, 3: 50000, 4: 50000, 5: 50000, 6: 50000, 7: 50000, 8: 50000, 9: 50000, 10: 50000, 11: 50000, 12: 50000, 13: 50000, 14: 50000, 15: 50000, 16: 50000, 17: 50000, 18: 50000, 19: 50000, 20: 50000, 21: 50000, 22: 46994, 23: 50000, 24: 50000, 25: 50000, 26: 50000, 27: 50000, 28: 50000, 29: 50000}\n",
      "1496994\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = []\n",
    "emoji_sample_counter = {}\n",
    "\n",
    "for dp in cleaned_dataset:\n",
    "    if dp.label in emoji_sample_counter:\n",
    "        if emoji_sample_counter[dp.label] < 50000:\n",
    "            sample_dataset.append(dp)\n",
    "            emoji_sample_counter[dp.label] += 1\n",
    "    else:\n",
    "        emoji_sample_counter[dp.label] = 1\n",
    "        sample_dataset.append(dp)\n",
    "print (emoji_sample_counter) \n",
    "print (len(sample_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197595\n",
      "149700\n",
      "149699\n"
     ]
    }
   ],
   "source": [
    "shuffle(sample_dataset)\n",
    "train_split = int(round(0.8*len(sample_dataset)))\n",
    "dev_split = train_split + int(round(0.5 * (len(sample_dataset) - train_split)))\n",
    "\n",
    "train_data = sample_dataset[:train_split]\n",
    "dev_data = sample_dataset[train_split:dev_split]\n",
    "test_data = sample_dataset[dev_split:]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(dev_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.csv', 'w') as f:\n",
    "    for datapoint in train_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dev.csv', 'w') as f:\n",
    "    for datapoint in dev_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.csv', 'w') as f:\n",
    "    for datapoint in test_data:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
