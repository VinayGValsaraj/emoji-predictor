{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from emoji import UNICODE_EMOJI, demojize, unicode_codes\n",
    "import html\n",
    "import nltk\n",
    "import re\n",
    "from utils import Indexer\n",
    "import string\n",
    "emoji_set = set(['ğŸ˜‚', 'ğŸ˜­', 'â¤', 'ğŸ˜', 'ğŸ”¥', 'ğŸ¤£', 'ğŸ’•', 'ğŸ™', 'âœ¨', 'ğŸ˜©', 'ğŸ’œ', 'ğŸ˜Š', 'ğŸ’€', 'ğŸ¤·', 'ğŸ‘€', 'ğŸ’™', 'ğŸƒ', 'ğŸ¤”', 'ğŸ˜˜', 'ğŸ‘', 'ğŸ™Œ', 'ğŸ‰', 'ğŸ’¯', 'ğŸ¤¦', 'ğŸ‘', 'ğŸ‘‰', 'ğŸ’–', 'ğŸ™„', 'ğŸ˜', 'ğŸ˜'])\n",
    "punc = string.punctuation.replace(\"'\", \"â€¦\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = text.replace(\"RT \", \"\")\n",
    "    text = text.replace(\"\\n\", \" \").lower()\n",
    "    #text = re.sub(r'[^\\w\\s]','',text)\n",
    "    words = text.split(\" \")\n",
    "\n",
    "    for word in words:\n",
    "        if \"@\" in word or word.startswith(\"http\"):\n",
    "            text = text.replace(word, \"\")\n",
    "            \n",
    "    text = text.translate(str.maketrans(\" \", \" \", punc))\n",
    "    text = html.unescape(text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emojis_in_text(text, emoji_set):\n",
    "    char_set = set(text)\n",
    "    #print(char_set)\n",
    "    all_emojis = emoji_set & char_set\n",
    "    \n",
    "    return all_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code mostly gotten from emoji package\n",
    "def clean_tweet(tweet):\n",
    "    delimiters=(\":\",\":\")\n",
    "    _DEFAULT_DELIMITER = \":\"\n",
    "    pattern = re.compile(u'(%s[a-zA-Z0-9\\+\\-_&.Ã´â€™Ã…Ã©Ã£Ã­Ã§()!#*]+%s)' % delimiters)\n",
    "    def replace(match):\n",
    "        mg = match.group(1).replace(delimiters[0], _DEFAULT_DELIMITER).replace(delimiters[1], _DEFAULT_DELIMITER)\n",
    "        return \"\"\n",
    "    demojized_tweet = demojize(tweet['processed_text'])\n",
    "    clean_text = pattern.sub(replace, demojized_tweet)\n",
    "    return ' '.join(clean_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading csv...\n",
      "done\n",
      "processing text\n",
      "processed 200000 tweets\n",
      "processed 400000 tweets\n",
      "processed 600000 tweets\n",
      "processed 800000 tweets\n",
      "processed 1000000 tweets\n",
      "processed 1200000 tweets\n",
      "processed 1400000 tweets\n",
      "processed 1600000 tweets\n",
      "processed 1800000 tweets\n",
      "processed 2000000 tweets\n",
      "processed 2200000 tweets\n",
      "processed 2400000 tweets\n",
      "processed 2600000 tweets\n",
      "processed 2800000 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "unique_tweet_ids = set()\n",
    "with open('twitter_october.csv', 'r') as csv_file:\n",
    "    print(\"reading csv...\")\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    print(\"done\")\n",
    "    print(\"processing text\")\n",
    "    count = 0\n",
    "    for row in csv_reader:\n",
    "        if row['text'] == 'text':\n",
    "            continue\n",
    "        row['processed_text'] = process_text(row['text'])\n",
    "        row['emojis_in_text'] = get_emojis_in_text(row['processed_text'], emoji_set)\n",
    "        if not row['emojis_in_text'] or row['id'] in unique_tweet_ids:\n",
    "            continue\n",
    "        tweets.append(row)\n",
    "        unique_tweet_ids.add(row['id'])\n",
    "        count += 1\n",
    "        if count % 200000 == 0:\n",
    "            print(\"processed\", count, \"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2936623"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_labels(tweet, indexer):\n",
    "    \n",
    "    all_emojis = tweet['emojis_in_text']\n",
    "    emojis = {}\n",
    "    c = Counter()\n",
    "    for emoji in all_emojis:\n",
    "        indexer.add_and_get_index(emoji)\n",
    "        c[emoji] += tweet['processed_text'].count(emoji)\n",
    "    \n",
    "    #print(all_emojis)\n",
    "    #print(\"txt\", tweet['processed_text'])\n",
    "    max_score = max(c.values())\n",
    "    labels = [indexer.index_of(k) for k in c if c[k] == max_score]\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPoint():\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(tweets, indexer, label_counter):\n",
    "    dataset = []\n",
    "    count = 0\n",
    "    for idx, tweet in enumerate(tweets):\n",
    "        try:\n",
    "            labels = get_labels(tweet, indexer)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        cleaned_text = clean_tweet(tweet)\n",
    "        for label in labels:\n",
    "            if indexer.get_object(label) is not 'â™€' and indexer.get_object(label) is not 'â™‚':\n",
    "                datapoint = DataPoint(cleaned_text, label)\n",
    "                dataset.append(datapoint)\n",
    "                label_counter[indexer.get_object(label)] += 1\n",
    "                \n",
    "        count += 1\n",
    "        if count % 500000 == 0:\n",
    "            print(\"created\", count, \"datapoints\")\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = Indexer()\n",
    "label_counter = Counter()\n",
    "dataset = create_dataset(tweets[0:50000], indexer, label_counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56928"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = indexer.objs_to_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('indexer.csv', 'w') as f:\n",
    "    for key in index_dict.keys():\n",
    "        f.write(\"%s|%s\\n\"%(key,index_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.csv', 'w') as f:\n",
    "    for datapoint in dataset:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(datapoint.label,datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
