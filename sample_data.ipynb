{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from utils import Indexer\n",
    "from random import shuffle\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataPoint():\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = []\n",
    "tknzr = TweetTokenizer()\n",
    "with open('cleaned_dataset.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        tokenized = tknzr.tokenize(row[1])\n",
    "        if set(tokenized) == set([\"UNK\"]):\n",
    "            continue\n",
    "        cleaned_dataset.append(DataPoint(row[1], int(row[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer = Indexer()\n",
    "with open('indexer.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        indexer.add_and_get_index(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ğŸ˜‚', 'ğŸ‘', 'ğŸ’™', 'ğŸ’¯', 'ğŸ˜', 'ğŸ”¥', 'ğŸ’•', 'ğŸ˜', 'ğŸ’€', 'ğŸ’œ', 'ğŸ‘', 'ğŸ¤·', 'ğŸ¤”', 'ğŸ˜©', 'ğŸ˜­', 'ğŸ¤£', 'ğŸ˜Š', 'â¤', 'ğŸ™Œ', 'âœ¨', 'ğŸ™', 'ğŸ‘€', 'ğŸ˜', 'ğŸ‘‰', 'ğŸ™„', 'ğŸ‰', 'ğŸ˜˜', 'ğŸ’–', 'ğŸƒ', 'ğŸ¤¦']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ğŸ’¯': 61490, 'â¤': 286901, 'ğŸ˜': 205144, 'ğŸ‘': 62793, 'ğŸ‘€': 69255, 'ğŸ˜‚': 617712, 'ğŸ”¥': 177376, 'ğŸ˜­': 297375, 'ğŸƒ': 66403, 'ğŸ™„': 50575, 'ğŸ’•': 105477, 'ğŸ¤£': 103230, 'ğŸ˜©': 88379, 'ğŸ˜': 46963, 'ğŸ¤¦': 57190, 'ğŸ’™': 66034, 'ğŸ’€': 68977, 'ğŸ‘': 57274, 'âœ¨': 91024, 'ğŸ’œ': 88554, 'ğŸ¤·': 69763, 'ğŸ‰': 61055, 'ğŸ˜Š': 76536, 'ğŸ’–': 53053, 'ğŸ‘‰': 60195, 'ğŸ™': 100460, 'ğŸ™Œ': 60690, 'ğŸ˜˜': 64757, 'ğŸ¤”': 63454, 'ğŸ˜': 51137}\n"
     ]
    }
   ],
   "source": [
    "emoji_sample_count = {}\n",
    "\n",
    "for dp in cleaned_dataset:\n",
    "    emoji_sample_count[indexer.get_object(dp.label)] = emoji_sample_count.get(indexer.get_object(dp.label), 0) + 1\n",
    "    \n",
    "print (emoji_sample_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we love the judges\n",
      "a clean and just energy transition for europe is possible no more public money for coal support 550 and make markets r\n",
      "happy people telling you â€œ oooh it â€™ s got dark early â€ day\n",
      "i want everybody to meet moores the cow\n",
      "i think we played some sexy football tonight proud captain of this team and this club yagunnersya m1Ã¶\n",
      "goodnight i love simona marilyn jules jasmine UNK and UNK uwu\n",
      "amazing animals deer\n",
      "i just want to huge her she deserves everything UNK\n",
      "who having a gender reveal next bc i wanna do the color wig\n",
      "you â€™ d think right apparently it â€™ s everywhere\n"
     ]
    }
   ],
   "source": [
    "for dp in cleaned_dataset[:5]:\n",
    "    print (dp.text)\n",
    "shuffle(cleaned_dataset)\n",
    "for dp in cleaned_dataset[:5]:\n",
    "    print (dp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329226\n"
     ]
    }
   ],
   "source": [
    "print (len(cleaned_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6: 50000, 4: 50000, 17: 50000, 0: 50000, 29: 50000, 16: 50000, 14: 50000, 27: 50000, 12: 50000, 24: 50000, 19: 50000, 15: 50000, 21: 50000, 25: 50000, 23: 50000, 22: 46963, 26: 50000, 20: 50000, 11: 50000, 9: 50000, 2: 50000, 5: 50000, 10: 50000, 1: 50000, 28: 50000, 18: 50000, 8: 50000, 13: 50000, 7: 50000, 3: 50000}\n",
      "1496963\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = []\n",
    "emoji_sample_counter = {}\n",
    "\n",
    "for dp in cleaned_dataset:\n",
    "    if dp.label in emoji_sample_counter:\n",
    "        if emoji_sample_counter[dp.label] < 50000:\n",
    "            sample_dataset.append(dp)\n",
    "            emoji_sample_counter[dp.label] += 1\n",
    "    else:\n",
    "        emoji_sample_counter[dp.label] = 1\n",
    "        sample_dataset.append(dp)\n",
    "print (emoji_sample_counter) \n",
    "print (len(sample_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sampled_dataset.csv', 'w') as f:\n",
    "    for datapoint in sample_dataset:\n",
    "        text = re.sub(r'[^\\w\\s]','', datapoint.text)\n",
    "        f.write(\"%s|%s\\n\"%(str(datapoint.label),datapoint.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
